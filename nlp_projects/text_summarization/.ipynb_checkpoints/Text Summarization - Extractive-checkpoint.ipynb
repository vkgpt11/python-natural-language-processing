{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization with NLTK - Extractive\n",
    "\n",
    "Going to build a TextRank algorithm, it is an unsupervised algorithm based on weighted-graph. It has been built using the Google's Page rank algorithm. \n",
    "\n",
    "Text Rank works as follows:\n",
    "1. Pre-process the text: remove stop words and stem the remaining words.\n",
    "2. Create a graph where vertices are sentences.\n",
    "3. Connect every sentence to every other sentence by an edge. The weight of the edge is how similar the two sentences are.\n",
    "4. Run the PageRank algorithm on the graph.\n",
    "5. Pick the vertices(sentences) with the highest PageRank score\n",
    "\n",
    "![](page_rank.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "Data is related to online store items reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = BeautifulSoup(open(\"positive.review\").read(),\"lxml\")\n",
    "positive_reviews =  positive_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a frequency summarizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencySummarizer:\n",
    "    def __init__(self, min_freq = 0.2, max_freq = 0.8):\n",
    "        self.min_freq = min_freq\n",
    "        self.max_freq = max_freq\n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation))\n",
    "        \n",
    "    def find_frequency(self,wordlist):\n",
    "        freq_words = nltk.FreqDist(wordlist)\n",
    "        my_new_dict = {}\n",
    "        maximum_freq = max(freq_words.values())\n",
    "        for key,value in freq_words.items():\n",
    "            freq_ratio = value/maximum_freq\n",
    "            if(freq_ratio > self.min_freq or freq_ratio < self.max_freq):\n",
    "                my_new_dict[key] = freq_ratio\n",
    "#         print(my_new_dict)\n",
    "        return my_new_dict\n",
    "    \n",
    "    \n",
    "    def word_tokenizer(self,s):\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        s = s.lower()  # downcase\n",
    "        tokens = nltk.tokenize.word_tokenize(s)  # split string into words (token)\n",
    "        tokens = [t for t in tokens if len(t) > 2]  # remove short words, they are probably not useful\n",
    "        tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens]  # put words into base form\n",
    "        tokens = [t for t in tokens if t not in self._stopwords]  # remove stopwords\n",
    "        return tokens  \n",
    "   \n",
    "\n",
    "    def summarize(self, document, n):\n",
    "        sent_tokens = sent_tokenize(document)\n",
    "        #print(sent_tokens)\n",
    "        word_sent = [self.word_tokenizer(s) for s in sent_tokens]\n",
    "        word_sent = sum(word_sent, [])\n",
    "        #print(word_sent)\n",
    "        frequencies_dict = self.find_frequency(word_sent)\n",
    "        sentence_ranks = {}\n",
    "        for i, sent in enumerate(sent_tokens):\n",
    "            word_tokens = self.word_tokenizer(sent)\n",
    "            freq_count = 0\n",
    "            for word in word_tokens:\n",
    "                freq = frequencies_dict[word]\n",
    "                freq_count+=freq\n",
    "            sentence_ranks[sent]=freq_count\n",
    "        return nlargest(n, sentence_ranks, key=sentence_ranks.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check the output -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Review Text **********\n",
      "\n",
      "I purchased this unit due to frequent blackouts in my area and 2 power supplies going bad.  It will run my cable modem, router, PC, and LCD monitor for 5 minutes.  This is more than enough time to save work and shut down.   Equally important, I know that my electronics are receiving clean power.\n",
      "\n",
      "I feel that this investment is minor compared to the loss of valuable data or the failure of equipment due to a power spike or an irregular power supply.\n",
      "\n",
      "As always, Amazon had it to me in <2 business days\n",
      "\n",
      "********** Review Summary **********\n",
      "I feel that this investment is minor compared to the loss of valuable data or the failure of equipment due to a power spike or an irregular power supply.\n",
      "\n",
      "I purchased this unit due to frequent blackouts in my area and 2 power supplies going bad.\n"
     ]
    }
   ],
   "source": [
    "print('********** Review Text **********')\n",
    "print(positive_reviews[0].text)\n",
    "fs = FrequencySummarizer()\n",
    "print('********** Review Summary **********')\n",
    "summary = fs.summarize(positive_reviews[0].text, 2)\n",
    "\n",
    "\n",
    "for x in summary:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weightage of each word in sentence\n",
    "\n",
    "` {'purchased': 0.25, 'unit': 0.25, 'due': 0.5, 'frequent': 0.25, 'blackout': 0.25, 'area': 0.25, 'power': 1.0, 'supply': 0.5, \n",
    " 'going': 0.25, 'bad': 0.25, 'run': 0.25, 'cable': 0.25, 'modem': 0.25, 'router': 0.25, 'lcd': 0.25, 'monitor': 0.25, \n",
    " 'minute': 0.25, 'enough': 0.25, 'time': 0.25, 'save': 0.25, 'work': 0.25, 'shut': 0.25, 'equally': 0.25, 'important': 0.25, \n",
    " 'know': 0.25, 'electronics': 0.25, 'receiving': 0.25, 'clean': 0.25, 'feel': 0.25, 'investment': 0.25, 'minor': 0.25, \n",
    " 'compared': 0.25, 'loss': 0.25, 'valuable': 0.25, 'data': 0.25, 'failure': 0.25, 'equipment': 0.25, 'spike': 0.25, \n",
    " 'irregular': 0.25, 'always': 0.25, 'amazon': 0.25, 'business': 0.25, 'day': 0.25} `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output -2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Review Text **********\n",
      "\n",
      "I am very happy with this product. It folds super slim, so traveling with it is a breeze! Pretty good sound - not Bose quality, but for the price, very respectable! I've had it almost a year, and it has been along on many weekend get-aways, and works great. I use it alot, so it was a good purchase for me\n",
      "\n",
      "********** Review Summary **********\n",
      "I've had it almost a year, and it has been along on many weekend get-aways, and works great.\n",
      "Pretty good sound - not Bose quality, but for the price, very respectable!\n"
     ]
    }
   ],
   "source": [
    "print('********** Review Text **********')\n",
    "print(positive_reviews[10].text)\n",
    "fs = FrequencySummarizer()\n",
    "print('********** Review Summary **********')\n",
    "summary = fs.summarize(positive_reviews[10].text, 2)\n",
    "\n",
    "\n",
    "for x in summary:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "    1. https://github.com/icoxfog417/awesome-text-summarization\n",
    "    2. https://glowingpython.blogspot.in/2014/09/text-summarization-with-nltk.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://speech-to-text-demo.ng.bluemix.net/?cm_mc_uid=52780117427715257205338&cm_mc_sid_50200000=56929031525720533897&cm_mc_sid_52640000=36056531525720533908"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
